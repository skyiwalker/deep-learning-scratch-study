{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.functions import softmax\n",
    "from rnnlm import Rnnlm\n",
    "from better_rnnlm import BetterRnnlm\n",
    "\n",
    "\n",
    "class RnnlmGen(Rnnlm):\n",
    "    def generate(self, start_id, skip_ids=None, sample_size=100):\n",
    "        word_ids = [start_id]\n",
    "\n",
    "        x = start_id\n",
    "        while len(word_ids) < sample_size:\n",
    "            x = np.array(x).reshape(1, 1)\n",
    "            score = self.predict(x)\n",
    "            p = softmax(score.flatten()) # p is numpy array and its shape is (10000,)\n",
    "\n",
    "            sampled = np.random.choice(len(p), size=1, p=p)\n",
    "            if (skip_ids is None) or (sampled not in skip_ids):\n",
    "                x = sampled\n",
    "                word_ids.append(int(x))\n",
    "\n",
    "        return word_ids\n",
    "\n",
    "    def get_state(self):\n",
    "        return self.lstm_layer.h, self.lstm_layer.c\n",
    "\n",
    "    def set_state(self, state):\n",
    "        self.lstm_layer.set_state(*state)\n",
    "\n",
    "\n",
    "class BetterRnnlmGen(BetterRnnlm):\n",
    "    def generate(self, start_id, skip_ids=None, sample_size=100):\n",
    "        word_ids = [start_id]\n",
    "\n",
    "        x = start_id\n",
    "        while len(word_ids) < sample_size:\n",
    "            x = np.array(x).reshape(1, 1)\n",
    "            score = self.predict(x).flatten()\n",
    "            p = softmax(score).flatten()\n",
    "\n",
    "            sampled = np.random.choice(len(p), size=1, p=p)\n",
    "            if (skip_ids is None) or (sampled not in skip_ids):\n",
    "                x = sampled\n",
    "                word_ids.append(int(x))\n",
    "\n",
    "        return word_ids\n",
    "\n",
    "    def get_state(self):\n",
    "        states = []\n",
    "        for layer in self.lstm_layers:\n",
    "            states.append((layer.h, layer.c))\n",
    "        return states\n",
    "\n",
    "    def set_state(self, states):\n",
    "        for layer, state in zip(self.lstm_layers, states):\n",
    "            layer.set_state(*state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you preamble duty arrogant polled effectively united deteriorating strictly roper conservatorship administrator rest miners upscale payments islands pursuing guide recalls sterling momentum werner wide giants balked failure plant behavior brink good positive southmark number current hotels listen penalty persuade accounted improving sounded called ufo crush distributes guards louis sec bullish mehl property\\/casualty nonetheless anacomp herself injured milk kkr viewers rated legg retains yourself thoughts plan shaking rupert installations oppenheimer ortega currently convey enabling par coverage reduces restoring situations belongs size predict chase monitors liquidation touchy tradition pcs equipment alternatively infrastructure conditions across-the-board tourism telephone splitting hart-scott-rodino carter recovering ambitions monopoly\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "corpus_size = len(corpus)\n",
    "\n",
    "model = RnnlmGen()\n",
    "# model.load_params('./Rnnlm.pkl')\n",
    "\n",
    "# start 문자와 skip 문자 설정\n",
    "start_word = 'you'\n",
    "start_id = word_to_id[start_word]\n",
    "skip_words = ['N', '<unk>', '$']\n",
    "skip_ids = [word_to_id[w] for w in skip_words]\n",
    "# 문장 생성\n",
    "word_ids = model.generate(start_id, skip_ids)\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "txt = txt.replace(' <eos>', '.\\n')\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습된 모델의 가중치 불러들이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you 've yet wait are going to see another member of lebanon who he is east would n't stem from a drink of the political negative.\n",
      " mr. templeton cabrera is the shortage of wyoming who forced out of the producers showing that messrs. gorbachev would n't be brought through the financial office of buick in the move that might two years.\n",
      " stephen r. breeden in the chairman of the filters showed the members of mr. davis 's findings mr. roman was thriving without the nsc 's political target of american express 's original.\n",
      " mr. roman said the\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "corpus_size = len(corpus)\n",
    "\n",
    "model = RnnlmGen()\n",
    "model.load_params('./Rnnlm.pkl')\n",
    "\n",
    "# start 문자와 skip 문자 설정\n",
    "start_word = 'you'\n",
    "start_id = word_to_id[start_word]\n",
    "skip_words = ['N', '<unk>', '$']\n",
    "skip_ids = [word_to_id[w] for w in skip_words]\n",
    "# 문장 생성\n",
    "word_ids = model.generate(start_id, skip_ids)\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "txt = txt.replace(' <eos>', '.\\n')\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 확률분포 기준 샘플링 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = [0.1,0.2,0.5,0.02,0.08,0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\n"
     ]
    }
   ],
   "source": [
    "sampled = np.random.choice(len(prob), size=1, p=prob)\n",
    "print(sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "\n",
    "for i in range(100):\n",
    "    sampled = np.random.choice(len(prob), size=1, p=prob)    \n",
    "    if sampled.item() in res:\n",
    "        res[sampled.item()] += 1\n",
    "    else:\n",
    "        res[sampled.item()] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 39, 1: 24, 4: 18, 0: 11, 5: 7, 3: 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# join함수의 사용예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isayyouarehandsome\n",
      "I say you are handsome\n",
      "I,say,you,are,handsome\n"
     ]
    }
   ],
   "source": [
    "strlist = ['I','say','you','are','handsome']\n",
    "print(''.join(strlist))\n",
    "print(' '.join(strlist))\n",
    "print(','.join(strlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Better RNNLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you could have a habit of talking about the program at ok he.\n",
      " i 's not coming to car his business.\n",
      " you know how the wrong turn are n't fear ralph is just getting the bad.\n",
      " when you come with news principals and got on the courtroom playing.\n",
      " i cut over the overseeing indian boxes they are considering and shows what the shot highlight during the community or his supermarket.\n",
      " the two other highly educated campaigns though mr. sohmer sent together with the heart of the dealership representative mentioned by other assurances that i should\n",
      "--------------------------------------------------\n",
      "the meaning of life is deciding whether it has a long history in which the own agreed to open an indictment.\n",
      " when an asset effort to coordinate its territory as a prospectus for employees and the tabloid for any type of money and appropriate controls would act before the los angeles financial condition say.\n",
      " it is whether to recent acquisitions the industry has disrupted its rights.\n",
      " the firms do n't have the more vulnerable names because of a reduction in the value of foreign companies.\n",
      " now the biggest policy of the bank says the mexican in the industrial sector has\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.np import *\n",
    "from rnnlm_gen import BetterRnnlmGen\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "corpus_size = len(corpus)\n",
    "\n",
    "\n",
    "model = BetterRnnlmGen()\n",
    "model.load_params('BetterRnnlm.pkl') # Downloaded from website!\n",
    "\n",
    "# start 문자와 skip 문자 설정\n",
    "start_word = 'you'\n",
    "start_id = word_to_id[start_word]\n",
    "skip_words = ['N', '<unk>', '$']\n",
    "skip_ids = [word_to_id[w] for w in skip_words]\n",
    "# 문장 생성\n",
    "word_ids = model.generate(start_id, skip_ids)\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "txt = txt.replace(' <eos>', '.\\n')\n",
    "\n",
    "print(txt)\n",
    "\n",
    "\n",
    "model.reset_state()\n",
    "\n",
    "start_words = 'the meaning of life is'\n",
    "start_ids = [word_to_id[w] for w in start_words.split(' ')]\n",
    "\n",
    "for x in start_ids[:-1]:\n",
    "    x = np.array(x).reshape(1, 1)\n",
    "    model.predict(x)\n",
    "\n",
    "word_ids = model.generate(start_ids[-1], skip_ids)\n",
    "word_ids = start_ids[:-1] + word_ids\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "txt = txt.replace(' <eos>', '.\\n')\n",
    "print('-' * 50)\n",
    "print(txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 7) (45000, 5)\n",
      "(5000, 7) (5000, 5)\n",
      "[ 3  0  2  0  0 11  5]\n",
      "[ 6  0 11  7  5]\n",
      "71+118 \n",
      "_189 \n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from dataset import sequence\n",
    "\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    sequence.load_data('addition.txt', seed=1984)\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "print(x_train.shape, t_train.shape)\n",
    "print(x_test.shape, t_test.shape)\n",
    "# (45000, 7) (45000, 5)\n",
    "# (5000, 7) (5000, 5)\n",
    "\n",
    "print(x_train[0])\n",
    "print(t_train[0])\n",
    "# [ 3  0  2  0  0 11  5]\n",
    "# [ 6  0 11  7  5]\n",
    "\n",
    "print(''.join([id_to_char[c] for c in x_train[0]]))\n",
    "print(''.join([id_to_char[c] for c in t_train[0]]))\n",
    "# 71+118\n",
    "# _189\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
